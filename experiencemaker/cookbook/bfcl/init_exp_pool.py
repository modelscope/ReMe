import json
import requests
import argparse
from pathlib import Path
from typing import List, Dict, Any
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed


def load_task_case(data_path: str, task_id: str | None) -> Dict[str, Any]:
    """æŒ‰ IDåŠ è½½å•æ¡ JSONL è®­ç»ƒç”¨ä¾‹ã€‚æ‰¾ä¸åˆ°å°±æŠ›é”™ã€‚"""
    if not Path(data_path).exists():
        raise FileNotFoundError(f"BFCL data file '{data_path}' not found")

    if task_id is None:
        raise ValueError("task_id is required")

    with open(data_path, "r", encoding="utf-8") as f:
        if str(task_id).isdigit():
            idx = int(task_id)
            for line_no, line in enumerate(f):
                if line_no == idx:
                    return json.loads(line)
            raise ValueError(f"Task case index {idx} not found in {data_path}")
        else:
            for line in f:
                data = json.loads(line)
                if data.get("id") == task_id:
                    return data
            raise ValueError(f"Task case id '{task_id}' not found in {data_path}")


def get_tool_prompt(tools):
    tool_prompt = "\n\n# Tools\n\nYou may call one or more functions to assist with the user query.\n\nYou are provided with function signatures within <tools></tools> XML tags:\n<tools>"
    for tool in tools:
        tool_prompt += "\n" + json.dumps(tool)
    tool_prompt += "\n</tools>\n\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n<tool_call>\n{\"name\": <function-name>, \"arguments\": <args-json-object>}\n</tool_call>"
    return tool_prompt


def group_trajectories_by_task_id(jsonl_entries: List[Dict[str, Any]]) -> List[List[Any]]:
    """
    æ ¹æ®task_idå­—æ®µå¯¹trajectoriesè¿›è¡Œåˆ†ç»„
    
    Args:
        jsonl_entries: JSONLæ¡ç›®åˆ—è¡¨
        
    Returns:
        List[List[Any]]: æŒ‰task_idåˆ†ç»„çš„trajectoryåˆ—è¡¨
    """
    # æŒ‰task_idåˆ†ç»„
    grouped = defaultdict(list)
    
    for entry in jsonl_entries:
        task_id = entry.get("task_id", "")
        taks_case = load_task_case("data/multiturn_data_base.jsonl", task_id)
        tools = taks_case.get("tools", [{}])
        from bfcl_utils import extract_tool_schema
        tool_schema = extract_tool_schema(tools)
        entry["task_history"][0]["content"] += get_tool_prompt(tool_schema)
        grouped[task_id].append(entry)
    
    # å¯¹æ¯ç»„åªä¿ç•™æœ€å¤§å’Œæœ€å°rewardçš„ä¸¤ä¸ª
    filtered_groups = []
    for key, trajectories in grouped.items():
        if len(trajectories) == 1:
            # åªæœ‰ä¸€ä¸ªtrajectoryï¼Œç›´æ¥ä¿ç•™
            filtered_groups.append(trajectories)
        elif len(trajectories) == 2:
            # æœ‰ä¸¤ä¸ªtrajectoryï¼Œç›´æ¥ä¿ç•™
            filtered_groups.append(trajectories)
        else:
            # å¤šä¸ªtrajectoryï¼Œé€‰æ‹©æœ€å¤§å’Œæœ€å°rewardçš„
            # import random
            # random.shuffle(trajectories)
            trajectories.sort(key=lambda t: t["reward"])
            min_reward_traj = trajectories[0]  # æœ€å°reward
            max_reward_traj = trajectories[-1]  # æœ€å¤§reward
            filtered_groups.append([min_reward_traj, max_reward_traj])
    
    return filtered_groups


def post_to_summarizer(trajectories: List[Any], service_url: str, workspace_id: str) -> Dict[str, Any]:
    """
    å°†trajectorieså‘é€åˆ°summarizeræœåŠ¡
    
    Args:
        trajectories: trajectoryåˆ—è¡¨
        service_url: æœåŠ¡URL
        workspace_id: å·¥ä½œç©ºé—´ID
        
    Returns:
        å“åº”ç»“æœ
    """
    trajectory_dicts = [{
        "task_id": traj["task_id"],
        "messages": traj["task_history"],
        "score": traj["reward"]
    } for traj in trajectories]

    request_data = {
        "traj_list": trajectory_dicts,
        "workspace_id": workspace_id
    }
    
    try:
        response = requests.post(f"{service_url}/summarizer", json=request_data)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        return {"error": str(e), "trajectories_count": len(trajectories)}


def process_trajectories_with_threads(grouped_trajectories: List[List[Any]], 
                                    service_url: str, 
                                    workspace_id: str, 
                                    n_threads: int = 4) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†trajectoriesç»„
    
    Args:
        grouped_trajectories: æŒ‰task_idåˆ†ç»„çš„trajectoryåˆ—è¡¨
        service_url: summarizeræœåŠ¡URL
        workspace_id: å·¥ä½œç©ºé—´ID
        n_threads: çº¿ç¨‹æ•°
        
    Returns:
        æ‰€æœ‰ç»“æœåˆ—è¡¨
    """
    results = []
    
    with ThreadPoolExecutor(max_workers=n_threads) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_group = {
            executor.submit(post_to_summarizer, group, service_url, workspace_id): i 
            for i, group in enumerate(grouped_trajectories)
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_group):
            group_index = future_to_group[future]
            try:
                result = future.result()
                result["group_index"] = group_index
                result["group_size"] = len(grouped_trajectories[group_index])
                results.append(result)
                print(f"âœ… Group {group_index} processed: {result.get('experience_list', 0) if 'experience_list' in result else 'error'}")
            except Exception as e:
                error_result = {
                    "group_index": group_index,
                    "group_size": len(grouped_trajectories[group_index]),
                    "error": str(e)
                }
                results.append(error_result)
                print(f"âŒ Group {group_index} failed: {e}")
    
    return results


def main():
    """
    ä¸»å‡½æ•°ï¼Œæ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(description='Convert JSONL to experiences using experience maker service')
    parser.add_argument('--jsonl_file', type=str, required=True, help='Path to the JSONL file')
    parser.add_argument('--service_url', type=str, default='http://localhost:8001', help='Experience maker service URL')
    parser.add_argument('--workspace_id', type=str, required=True, help='Workspace ID for the experience')
    parser.add_argument('--output_file', type=str, help='Output file to save results (optional)')
    parser.add_argument('--n_threads', type=int, default=4, help='Number of threads for processing')
    
    args = parser.parse_args()
    
    print(f"Processing JSONL file: {args.jsonl_file}")
    print(f"Service URL: {args.service_url}")
    print(f"Workspace ID: {args.workspace_id}")
    print(f"Threads: {args.n_threads}")
    
    # è¯»å–JSONLæ–‡ä»¶
    try:
        with open(args.jsonl_file, "r") as f:
            data = [json.loads(line) for line in f]
        print(f"Loaded {len(data)} entries from JSONL file")
    except Exception as e:
        print(f"Error reading JSONL file: {e}")
        return
    
    # åˆ†ç»„å¤„ç†
    grouped_trajectories = group_trajectories_by_task_id(data)
    print(f"Total groups: {len(grouped_trajectories)}")
    
    # å¤šçº¿ç¨‹å¤„ç†
    results = process_trajectories_with_threads(
        grouped_trajectories, 
        args.service_url, 
        args.workspace_id,
        n_threads=args.n_threads
    )
    
    print(f"Processed {len(results)} groups")
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if 'error' not in r)
    error_count = len(results) - success_count
    total_experiences = sum(len(r.get('experiences', [])) for r in results if 'experiences' in r)

    
    print(f"âœ… Success: {success_count}")
    print(f"âŒ Errors: {error_count}")
    print(f"ğŸ“Š Total experiences created: {total_experiences}")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    if args.output_file:
        try:
            summary = {
                "workspace_id": args.workspace_id,
                "jsonl_file": args.jsonl_file,
                "total_groups": len(grouped_trajectories),
                "success_count": success_count,
                "error_count": error_count,
                "total_experiences": total_experiences,
                "results": results
            }
            
            with open(args.output_file, 'w') as f:
                json.dump(summary, f, indent=2)
            print(f"Results saved to: {args.output_file}")
        except Exception as e:
            print(f"Error saving results: {e}")


# ä¿æŒåŸæœ‰çš„ä½¿ç”¨ç¤ºä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰
if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    import sys
    if len(sys.argv) > 1:
        # ä½¿ç”¨æ–°çš„å‘½ä»¤è¡Œæ¥å£
        main()
    else:
        # ä¿æŒåŸæœ‰çš„è¡Œä¸ºï¼ˆå‘åå…¼å®¹ï¼‰
        print("Running in compatibility mode...")
        with open("exp_result/bfcl-multi-turn-train50_wo-exp-w-think-mix-8b&14b&32b.jsonl", "r") as f:
            data = [json.loads(line) for line in f]
        
        # åˆ†ç»„
        grouped_trajectories = group_trajectories_by_task_id(data)
        print(f"Total groups: {len(grouped_trajectories)}")
        
        results = process_trajectories_with_threads(
            grouped_trajectories, 
            "http://localhost:8003", 
            "bfcl_train50_qwen3_mix_32b&8b&14b_extract_compare_validate_categorized-noshuffle",
            n_threads=4
        )
        print(f"Processed {len(results)} groups")