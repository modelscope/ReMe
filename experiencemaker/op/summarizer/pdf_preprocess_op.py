#!/usr/bin/env python3
"""
MinerU PDF å¤„ç†å™¨
è¿”å› Markdown å†…å®¹å’Œç»“æ„åŒ–çš„ content_list
"""

import os
import json
import subprocess
import tempfile
import logging
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional, Union
import platform
import re


class MinerUPDFProcessor:
    """
    åŸºäº MinerU çš„ PDF å¤„ç†å™¨
    ä»¿ç…§ RAGAnything çš„å¤„ç†é€»è¾‘ï¼Œä½†ç‹¬ç«‹ä½¿ç”¨ MinerU
    """

    def __init__(self, log_level: str = "INFO"):
        """
        åˆå§‹åŒ–å¤„ç†å™¨

        Args:
            log_level: æ—¥å¿—çº§åˆ« ("DEBUG", "INFO", "WARNING", "ERROR")
        """
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=getattr(logging, log_level.upper()),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)

        # æ£€æŸ¥ MinerU å®‰è£…
        if not self.check_mineru_installation():
            raise RuntimeError(
                "MinerU æœªæ­£ç¡®å®‰è£…ã€‚è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š\n"
                "pip install -U 'mineru[core]' æˆ– uv pip install -U 'mineru[core]'"
            )

    def check_mineru_installation(self) -> bool:
        """æ£€æŸ¥ MinerU æ˜¯å¦æ­£ç¡®å®‰è£…"""
        try:
            subprocess_kwargs = {
                "capture_output": True,
                "text": True,
                "check": True,
                "encoding": "utf-8",
                "errors": "ignore",
            }

            # Windows ä¸‹éšè—æ§åˆ¶å°çª—å£
            if platform.system() == "Windows":
                subprocess_kwargs["creationflags"] = subprocess.CREATE_NO_WINDOW

            result = subprocess.run(["mineru", "--version"], **subprocess_kwargs)
            self.logger.debug(f"MinerU ç‰ˆæœ¬: {result.stdout.strip()}")
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            return False

    def _run_mineru_command(
            self,
            input_path: Union[str, Path],
            output_dir: Union[str, Path],
            method: str = "auto",
            lang: Optional[str] = None,
            backend: str = "pipeline",
            start_page: Optional[int] = None,
            end_page: Optional[int] = None,
            formula: bool = True,
            table: bool = True,
            device: Optional[str] = None,
            source: str = "modelscope",
            vlm_url: Optional[str] = None,
    ) -> None:
        """
        è¿è¡Œ MinerU å‘½ä»¤è¡Œå·¥å…·

        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            method: è§£ææ–¹æ³• (auto, txt, ocr)
            lang: æ–‡æ¡£è¯­è¨€ï¼Œç”¨äº OCR ä¼˜åŒ–
            backend: è§£æåç«¯
            start_page: èµ·å§‹é¡µç  (0-based)
            end_page: ç»“æŸé¡µç  (0-based)
            formula: å¯ç”¨å…¬å¼è§£æ
            table: å¯ç”¨è¡¨æ ¼è§£æ
            device: æ¨ç†è®¾å¤‡
            source: æ¨¡å‹æ¥æº
            vlm_url: VLM æœåŠ¡å™¨ URLï¼ˆå½“ backend ä¸º vlm-sglang-client æ—¶éœ€è¦ï¼‰
        """
        cmd = [
            "mineru",
            "-p", str(input_path),
            "-o", str(output_dir),
            "-m", method,
            # "-b", backend,
            # "--source", source,
        ]

        # æ·»åŠ å¯é€‰å‚æ•°
        if lang:
            cmd.extend(["-l", lang])
        if start_page is not None:
            cmd.extend(["-s", str(start_page)])
        if end_page is not None:
            cmd.extend(["-e", str(end_page)])
        if not formula:
            cmd.extend(["-f", "false"])
        if not table:
            cmd.extend(["-t", "false"])
        if device:
            cmd.extend(["-d", device])
        if vlm_url:
            cmd.extend(["-u", vlm_url])

        try:
            subprocess_kwargs = {
                "capture_output": True,
                "text": True,
                "check": True,
                "encoding": "utf-8",
                "errors": "ignore",
            }

            # Windows ä¸‹éšè—æ§åˆ¶å°çª—å£
            if platform.system() == "Windows":
                subprocess_kwargs["creationflags"] = subprocess.CREATE_NO_WINDOW

            self.logger.info(f"æ‰§è¡Œ MinerU å‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, **subprocess_kwargs)

            self.logger.info("MinerU å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
            if result.stdout:
                self.logger.debug(f"MinerU è¾“å‡º: {result.stdout}")

        except subprocess.CalledProcessError as e:
            self.logger.error(f"MinerU å‘½ä»¤æ‰§è¡Œé”™è¯¯: {e}")
            if e.stderr:
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {e.stderr}")
            raise
        except FileNotFoundError:
            raise RuntimeError(
                "mineru å‘½ä»¤æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿ MinerU 2.0 å·²æ­£ç¡®å®‰è£…ï¼š\n"
                "pip install -U 'mineru[core]' æˆ– uv pip install -U 'mineru[core]'"
            )

    def _read_output_files(
            self,
            output_dir: Path,
            file_stem: str,
            method: str = "auto"
    ) -> Tuple[List[Dict[str, Any]], str]:
        """
        è¯»å– MinerU ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶

        Args:
            output_dir: è¾“å‡ºç›®å½•
            file_stem: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            method: è§£ææ–¹æ³•

        Returns:
            Tuple[List[Dict[str, Any]], str]: (content_list, markdown_content)
        """
        # æŸ¥æ‰¾ç”Ÿæˆçš„æ–‡ä»¶
        md_file = output_dir / f"{file_stem}.md"
        json_file = output_dir / f"{file_stem}_content_list.json"
        images_base_dir = output_dir

        # æ£€æŸ¥å­ç›®å½•ç»“æ„
        file_stem_subdir = output_dir / file_stem
        if file_stem_subdir.exists():
            md_file = file_stem_subdir / method / f"{file_stem}.md"
            json_file = file_stem_subdir / method / f"{file_stem}_content_list.json"
            images_base_dir = file_stem_subdir / method

        # è¯»å– Markdown å†…å®¹
        md_content = ""
        if md_file.exists():
            try:
                with open(md_file, "r", encoding="utf-8") as f:
                    md_content = f.read()
                self.logger.info(f"æˆåŠŸè¯»å– Markdown æ–‡ä»¶: {md_file}")
            except Exception as e:
                self.logger.warning(f"æ— æ³•è¯»å– Markdown æ–‡ä»¶ {md_file}: {e}")
        else:
            self.logger.warning(f"Markdown æ–‡ä»¶ä¸å­˜åœ¨: {md_file}")

        # è¯»å– JSON å†…å®¹åˆ—è¡¨
        content_list = []
        if json_file.exists():
            try:
                with open(json_file, "r", encoding="utf-8") as f:
                    content_list = json.load(f)

                # ä¿®å¤ç›¸å¯¹è·¯å¾„ä¸ºç»å¯¹è·¯å¾„
                self.logger.info(f"ä¿®å¤å›¾ç‰‡è·¯å¾„ï¼ŒåŸºç¡€ç›®å½•: {images_base_dir}")
                for item in content_list:
                    if isinstance(item, dict):
                        for field_name in ["img_path", "table_img_path", "equation_img_path"]:
                            if field_name in item and item[field_name]:
                                img_path = item[field_name]
                                if not os.path.isabs(img_path):
                                    absolute_img_path = (images_base_dir / img_path).resolve()
                                    item[field_name] = str(absolute_img_path)
                                    self.logger.debug(f"æ›´æ–° {field_name}: {img_path} -> {item[field_name]}")

                self.logger.info(f"æˆåŠŸè¯»å– JSON æ–‡ä»¶: {json_file}, åŒ…å« {len(content_list)} ä¸ªå†…å®¹å—")

            except Exception as e:
                self.logger.warning(f"æ— æ³•è¯»å– JSON æ–‡ä»¶ {json_file}: {e}")
        else:
            self.logger.warning(f"JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")

        return content_list, md_content

    def process_pdf(
            self,
            pdf_path: Union[str, Path],
            output_dir: Optional[Union[str, Path]] = None,
            method: str = "auto",
            lang: Optional[str] = None,
            backend: str = "pipeline",
            **kwargs
    ) -> Tuple[List[Dict[str, Any]], str]:
        """
        å¤„ç† PDF æ–‡ä»¶

        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤åœ¨ PDF æ–‡ä»¶åŒç›®å½•ä¸‹åˆ›å»ºï¼‰
            method: è§£ææ–¹æ³• ("auto", "txt", "ocr")
            lang: æ–‡æ¡£è¯­è¨€ï¼Œç”¨äº OCR ä¼˜åŒ– (å¦‚ "ch", "en", "ja")
            backend: è§£æåç«¯ ("pipeline", "vlm-transformers", "vlm-sglang-engine", "vlm-sglang-client")
            **kwargs: å…¶ä»– MinerU å‚æ•°

        Returns:
            Tuple[List[Dict[str, Any]], str]: (content_list, markdown_content)

        Raises:
            FileNotFoundError: PDF æ–‡ä»¶ä¸å­˜åœ¨
            RuntimeError: MinerU å¤„ç†å¤±è´¥
        """
        # è½¬æ¢ä¸º Path å¯¹è±¡
        pdf_path = Path(pdf_path)
        if not pdf_path.exists():
            raise FileNotFoundError(f"PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")

        if not pdf_path.suffix.lower() == '.pdf':
            raise ValueError(f"æ–‡ä»¶ä¸æ˜¯ PDF æ ¼å¼: {pdf_path}")

        name_without_suffix = pdf_path.stem

        # å‡†å¤‡è¾“å‡ºç›®å½•
        if output_dir:
            base_output_dir = Path(output_dir)
        else:
            base_output_dir = pdf_path.parent / "mineru_output"

        base_output_dir.mkdir(parents=True, exist_ok=True)

        try:
            # è¿è¡Œ MinerU å‘½ä»¤
            self.logger.info(f"å¼€å§‹å¤„ç† PDF æ–‡ä»¶: {pdf_path}")

            self._run_mineru_command(
                input_path=pdf_path,
                output_dir=base_output_dir,
                method=method,
                lang=lang,
                backend=backend,
                **kwargs
            )

            # è¯»å–ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶
            backend_method = method
            if backend.startswith("vlm-"):
                backend_method = "vlm"

            content_list, markdown_content = self._read_output_files(
                base_output_dir, name_without_suffix, method=backend_method
            )

            # ç»Ÿè®¡å¤„ç†ç»“æœ
            content_stats = {}
            for item in content_list:
                if isinstance(item, dict):
                    content_type = item.get("type", "unknown")
                    content_stats[content_type] = content_stats.get(content_type, 0) + 1

            self.logger.info(f"PDF å¤„ç†å®Œæˆ! æå–äº† {len(content_list)} ä¸ªå†…å®¹å—")
            self.logger.info("å†…å®¹ç±»å‹ç»Ÿè®¡:")
            for content_type, count in content_stats.items():
                self.logger.info(f"  - {content_type}: {count}")

            return content_list, markdown_content

        except Exception as e:
            self.logger.error(f"å¤„ç† PDF æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            raise

    def save_results(
            self,
            content_list: List[Dict[str, Any]],
            markdown_content: str,
            output_path: Union[str, Path],
            save_markdown: bool = True,
            save_json: bool = True,
            indent: int = 2
    ) -> Dict[str, Path]:
        """
        ä¿å­˜å¤„ç†ç»“æœåˆ°æ–‡ä»¶

        Args:
            content_list: å†…å®¹åˆ—è¡¨
            markdown_content: Markdown å†…å®¹
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
            save_markdown: æ˜¯å¦ä¿å­˜ Markdown æ–‡ä»¶
            save_json: æ˜¯å¦ä¿å­˜ JSON æ–‡ä»¶
            indent: JSON æ–‡ä»¶ç¼©è¿›

        Returns:
            Dict[str, Path]: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        output_path = Path(output_path)
        saved_files = {}

        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜ Markdown æ–‡ä»¶
            if save_markdown and markdown_content:
                md_path = output_path.with_suffix('.md')
                with open(md_path, 'w', encoding='utf-8') as f:
                    f.write(markdown_content)
                saved_files['markdown'] = md_path
                self.logger.info(f"Markdown æ–‡ä»¶å·²ä¿å­˜: {md_path}")

            # ä¿å­˜ JSON æ–‡ä»¶
            if save_json and content_list:
                json_path = output_path.with_suffix('.json')
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(content_list, f, indent=indent, ensure_ascii=False)
                saved_files['json'] = json_path
                self.logger.info(f"JSON æ–‡ä»¶å·²ä¿å­˜: {json_path}")

            return saved_files

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            raise


def chunk_pdf_content(content_list: List[Dict[str, Any]], max_length: int = 4000) -> List[str]:
    """
    å°†MinerUè§£æçš„content_liståˆ†å‰²æˆæŒ‡å®šé•¿åº¦çš„æ–‡æœ¬å—

    Args:
        content_list: MinerUè§£æçš„å†…å®¹åˆ—è¡¨
        max_length: æ¯ä¸ªchunkçš„æœ€å¤§å­—ç¬¦é•¿åº¦

    Returns:
        List[str]: åˆ†å—åçš„æ–‡æœ¬åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æœ¬éƒ½å¸¦æœ‰chunkæ ‡è®°
    """

    def extract_text(item):
        """æå–å•ä¸ªitemçš„æ–‡æœ¬"""
        if item.get("type") == "text":
            text = item.get("text", "").strip()
            if not text:
                return ""
            # å¦‚æœæ˜¯æ ‡é¢˜ï¼Œæ·»åŠ #æ ‡è®°
            level = item.get("text_level", 0)
            if level > 0:
                return f"{'#' * min(level, 6)} {text}"
            return text

        elif item.get("type") == "table":
            parts = []
            if item.get("table_caption"):
                parts.append("è¡¨æ ¼: " + " | ".join(item["table_caption"]))
            if item.get("table_body"):
                # ç®€å•æ¸…ç†HTMLæ ‡ç­¾
                table_text = re.sub(r'<[^>]+>', ' | ', item["table_body"])
                table_text = re.sub(r'\s+', ' ', table_text).strip()
                parts.append(table_text)
            return "\n".join(parts) if parts else ""

        elif item.get("type") == "image":
            if item.get("image_caption"):
                return "å›¾ç‰‡: " + " | ".join(item["image_caption"])
            return ""

        return ""

    # æå–æ‰€æœ‰æ–‡æœ¬
    all_text = ""
    for item in content_list:
        text = extract_text(item)
        if text.strip():
            all_text += text + "\n"

    if not all_text.strip():
        return []

    # åˆ†å‰²æˆchunks
    chunks = []
    current_chunk = ""

    for line in all_text.split('\n'):
        if len(current_chunk) + len(line) + 1 > max_length and current_chunk:
            chunks.append(current_chunk.strip())
            current_chunk = line
        else:
            current_chunk += line + "\n" if current_chunk else line

    # æ·»åŠ æœ€åä¸€ä¸ªchunk
    if current_chunk.strip():
        chunks.append(current_chunk.strip())

    # æ·»åŠ æ ‡è®°
    total_chunks = len(chunks)
    marked_chunks = []
    for i, chunk in enumerate(chunks):
        header = f"=== CHUNK {i + 1}/{total_chunks} ({len(chunk)}å­—ç¬¦) ===\n"
        marked_chunks.append(header + chunk)

    return marked_chunks


def main():
    """ä¸»å‡½æ•° - ç›´æ¥å¤„ç† PDF æ–‡ä»¶"""

    # é…ç½®è¾“å…¥å’Œè¾“å‡ºè·¯å¾„
    input_pdf_path = "/Users/dengjiaji/Downloads/bandaoti_research.pdf"  # ä¿®æ”¹ä¸ºä½ çš„ PDF æ–‡ä»¶è·¯å¾„
    output_dir = "/Users/dengjiaji/Downloads/bandaoti_research"  # ä¿®æ”¹ä¸ºä½ çš„è¾“å‡ºç›®å½•

    try:
        # åˆ›å»ºå¤„ç†å™¨
        processor = MinerUPDFProcessor(log_level="INFO")

        # å¤„ç† PDF æ–‡ä»¶ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰
        print(f"å¼€å§‹å¤„ç† PDF: {input_pdf_path}")
        content_list, markdown_content = processor.process_pdf(
            pdf_path=input_pdf_path,
            output_dir=output_dir,
            method="auto",  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³è§£ææ–¹æ³•
            backend="pipeline"  # ä½¿ç”¨é»˜è®¤åç«¯
        )

        # ä¿å­˜ç»“æœåˆ°è¾“å‡ºç›®å½•
        # output_base = Path(output_dir) / Path(input_pdf_path).stem
        # saved_files = processor.save_results(
        #     content_list=content_list,
        #     markdown_content=markdown_content,
        #     output_path=output_base
        # )

        # æ˜¾ç¤ºç»“æœ
        print(f"\nâœ… å¤„ç†å®Œæˆ!")
        print(f"ğŸ“„ æå–å†…å®¹å—æ•°é‡: {len(content_list)}")
        print(f"ğŸ“ Markdown å†…å®¹é•¿åº¦: {len(markdown_content)} å­—ç¬¦")
        print(f"\nğŸ’¾ ä¿å­˜çš„æ–‡ä»¶:")
        # for file_type, file_path in saved_files.items():
        #     print(f"  {file_type}: {file_path}")

        # æ˜¾ç¤ºå†…å®¹ç±»å‹ç»Ÿè®¡
        content_stats = {}
        for item in content_list:
            if isinstance(item, dict):
                content_type = item.get("type", "unknown")
                content_stats[content_type] = content_stats.get(content_type, 0) + 1

        print(f"\nğŸ“Š å†…å®¹ç±»å‹ç»Ÿè®¡:")
        for content_type, count in content_stats.items():
            print(f"  {content_type}: {count}")

        return content_list, markdown_content

    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print("è¯·æ£€æŸ¥ input_pdf_path æ˜¯å¦æ­£ç¡®")
        return None, None
    except Exception as e:
        print(f"âŒ å¤„ç†é”™è¯¯: {e}")
        return None, None


if __name__ == "__main__":
    # main()
    with open("/Users/dengjiaji/Downloads/bandaoti_research/bandaoti_research/auto/bandaoti_research_content_list.json", 'r', encoding='utf-8') as f:
        content_list = json.load(f)

    # ç”Ÿæˆchunks
    chunks = chunk_pdf_content(content_list, max_length=10000)
    print("len(chunks)", len(chunks))
